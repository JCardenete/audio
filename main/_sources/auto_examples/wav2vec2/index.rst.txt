:orphan:



.. _sphx_glr_auto_examples_wav2vec2:

Wav2Vec2 Tutorials
==================



.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="**Author**: `Moto Hira &lt;moto@fb.com&gt;`__">

.. only:: html

 .. figure:: /auto_examples/wav2vec2/images/thumb/sphx_glr_speech_recognition_pipeline_tutorial_thumb.png
     :alt: Speech Recognition with Wav2Vec2

     :ref:`sphx_glr_auto_examples_wav2vec2_speech_recognition_pipeline_tutorial.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_examples/wav2vec2/speech_recognition_pipeline_tutorial

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="**Author** `Moto Hira &lt;moto@fb.com&gt;`__">

.. only:: html

 .. figure:: /auto_examples/wav2vec2/images/thumb/sphx_glr_forced_alignment_tutorial_thumb.png
     :alt: Forced Alignment with Wav2Vec2

     :ref:`sphx_glr_auto_examples_wav2vec2_forced_alignment_tutorial.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_examples/wav2vec2/forced_alignment_tutorial
.. raw:: html

    <div class="sphx-glr-clear"></div>



.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-gallery


  .. container:: sphx-glr-download sphx-glr-download-python

    :download:`Download all examples in Python source code: wav2vec2_python.zip </auto_examples/wav2vec2/wav2vec2_python.zip>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

    :download:`Download all examples in Jupyter notebooks: wav2vec2_jupyter.zip </auto_examples/wav2vec2/wav2vec2_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
