{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# ASR Inference with CTC Decoder\n\n**Author**: `Caroline Chen <carolinechen@fb.com>`__\n\nThis tutorial shows how to perform speech recognition inference using a\nCTC beam search decoder with lexicon constraint and KenLM language model\nsupport. We demonstrate this on a pretrained wav2vec 2.0 model trained\nusing CTC loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n\nRunning ASR inference using a CTC Beam Search decoder with a KenLM\nlanguage model and lexicon constraint requires the following components\n\n-  Acoustic Model: model predicting phonetics from audio waveforms\n-  Tokens: the possible predicted tokens from the acoustic model\n-  Lexicon: mapping between possible words and their corresponding\n   tokens sequence\n-  KenLM: n-gram language model trained with the `KenLM\n   library <https://kheafield.com/code/kenlm/>`__\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation\n\nFirst we import the necessary utilities and fetch the data that we are\nworking with\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport IPython\nimport torch\nimport torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acoustic Model and Data\n\nWe use the pretrained `Wav2Vec 2.0 <https://arxiv.org/abs/2006.11477>`__\nBase model that is finetuned on 10 min of the `LibriSpeech\ndataset <http://www.openslr.org/12>`__, which can be loaded in using\n``torchaudio.pipelines``. For more detail on running Wav2Vec 2.0 speech\nrecognition pipelines in torchaudio, please refer to `this\ntutorial <https://pytorch.org/audio/main/tutorials/speech_recognition_pipeline_tutorial.html>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_10M\nacoustic_model = bundle.get_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will load a sample from the LibriSpeech test-other dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hub_dir = torch.hub.get_dir()\n\nspeech_url = \"https://pytorch.s3.amazonaws.com/torchaudio/tutorial-assets/ctc-decoding/8461-258277-0000.wav\"\nspeech_file = f\"{hub_dir}/speech.wav\"\n\ntorch.hub.download_url_to_file(speech_url, speech_file)\n\nIPython.display.Audio(speech_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The transcript corresponding to this audio file is\n``\"when it was the seven hundred and eighteenth night\"``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "waveform, sample_rate = torchaudio.load(speech_file)\n\nif sample_rate != bundle.sample_rate:\n    waveform = torchaudio.functional.resample(waveform, sample_rate, bundle.sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Files for Decoder\n\nNext, we load in our token, lexicon, and KenLM data, which are used by\nthe decoder to predict words from the acoustic model output.\n\nNote: this cell may take a couple of minutes to run, as the language\nmodel can be large\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tokens\n\nThe tokens are the possible symbols that the acoustic model can predict,\nincluding the blank and silent symbols.\n\n::\n\n   # tokens.txt\n   _\n   |\n   e\n   t\n   ...\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "token_url = \"https://pytorch.s3.amazonaws.com/torchaudio/tutorial-assets/ctc-decoding/tokens-w2v2.txt\"\ntoken_file = f\"{hub_dir}/token.txt\"\ntorch.hub.download_url_to_file(token_url, token_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Lexicon\n\nThe lexicon is a mapping from words to their corresponding tokens\nsequence, and is used to restrict the search space of the decoder to\nonly words from the lexicon. The expected format of the lexicon file is\na line per word, with a word followed by its space-split tokens.\n\n::\n\n   # lexcion.txt\n   a a |\n   able a b l e |\n   about a b o u t |\n   ...\n   ...\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lexicon_url = \"https://pytorch.s3.amazonaws.com/torchaudio/tutorial-assets/ctc-decoding/lexicon-librispeech.txt\"\nlexicon_file = f\"{hub_dir}/lexicon.txt\"\ntorch.hub.download_url_to_file(lexicon_url, lexicon_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### KenLM\n\nThis is an n-gram language model trained with the `KenLM\nlibrary <https://kheafield.com/code/kenlm/>`__. Both the ``.arpa`` or\nthe binarized ``.bin`` LM can be used, but the binary format is\nrecommended for faster loading.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kenlm_url = \"https://pytorch.s3.amazonaws.com/torchaudio/tutorial-assets/ctc-decoding/4-gram-librispeech.bin\"\nkenlm_file = f\"{hub_dir}/kenlm.bin\"\ntorch.hub.download_url_to_file(kenlm_url, kenlm_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Construct Beam Search Decoder\n\nThe decoder can be constructed using the ``kenlm_lexicon_decoder``\nfactory function from ``torchaudio.prototype.ctc_decoder``. In addition\nto the previously mentioned components, it also takes in various beam\nsearch decoding parameters and token/word parameters. The full list of\nparameters can be found\n`here <https://pytorch.org/audio/main/prototype.html#kenlm-lexicon-decoder>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchaudio.prototype.ctc_decoder import kenlm_lexicon_decoder\n\nbeam_search_decoder = kenlm_lexicon_decoder(\n    lexicon=lexicon_file,\n    tokens=token_file,\n    kenlm=kenlm_file,\n    nbest=1,\n    beam_size=1500,\n    beam_size_token=50,\n    lm_weight=3.23,\n    word_score=-1.39,\n    unk_score=float(\"-inf\"),\n    sil_score=0,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Greedy Decoder\n\nFor comparison against the beam search decoder, we also construct a\nbasic greedy decoder.\\ **bold text**\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GreedyCTCDecoder(torch.nn.Module):\n    def __init__(self, labels, blank=0):\n        super().__init__()\n        self.labels = labels\n        self.blank = blank\n\n    def forward(self, emission: torch.Tensor) -> str:\n        \"\"\"Given a sequence emission over labels, get the best path string\n        Args:\n          emission (Tensor): Logit tensors. Shape `[num_seq, num_label]`.\n\n        Returns:\n          str: The resulting transcript\n        \"\"\"\n        indices = torch.argmax(emission, dim=-1)  # [num_seq,]\n        indices = torch.unique_consecutive(indices, dim=-1)\n        indices = [i for i in indices if i != self.blank]\n        return \"\".join([self.labels[i] for i in indices])\n\n\ngreedy_decoder = GreedyCTCDecoder(labels=bundle.get_labels())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Inference\n\nNow that we have the data, acoustic model, and decoder, we can perform\ninference. Recall the transcript corresponding to the waveform is\n``\"when it was the seven hundred and eighteenth night\"``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "emission, _ = acoustic_model(waveform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the beam search decoder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "beam_search_result = beam_search_decoder(emission)\nbeam_search_transcript = \" \".join(beam_search_result[0][0].words).lower().strip()\nprint(beam_search_transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the greedy decoder:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "greedy_result = greedy_decoder(emission[0])\ngreedy_transcript = greedy_result.replace(\"|\", \" \").lower().strip()\nprint(greedy_transcript)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the transcript with the lexicon-constrained beam search\ndecoder consists of real words, while the greedy decoder can predict\nincorrectly spelled words like \u201chundrad\u201d.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}