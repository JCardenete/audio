


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Text-to-speech with torchaudio Tacotron2 &mdash; Torchaudio main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Text-to-Speech" href="index.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/audio/versions.html'>main  &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torchaudio.html">torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backend.html">torchaudio.backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../functional.html">torchaudio.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transforms.html">torchaudio.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">torchaudio.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">torchaudio.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipelines.html">torchaudio.pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sox_effects.html">torchaudio.sox_effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compliance.kaldi.html">torchaudio.compliance.kaldi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../kaldi_io.html">torchaudio.kaldi_io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">torchaudio.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prototype.html">torchaudio.prototype.emformer</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../wav2vec2/index.html">Wav2Vec2 Tutorials</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Text-to-Speech</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Text-to-Speech</a> &gt;</li>
        
      <li>Text-to-speech with torchaudio Tacotron2</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_examples/tts/tacotron2_pipeline_tutorial.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
    

    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">auto_examples/tts/tacotron2_pipeline_tutorial</div>

      <div id="google-colab-link">
        <img class="call-to-action-img" src="../../_static/images/pytorch-colab.svg"/>
        <div class="call-to-action-desktop-view">Run in Google Colab</div>
        <div class="call-to-action-mobile-view">Colab</div>
      </div>
      <div id="download-notebook-link">
        <img class="call-to-action-notebook-img" src="../../_static/images/pytorch-download.svg"/>
        <div class="call-to-action-desktop-view">Download Notebook</div>
        <div class="call-to-action-mobile-view">Notebook</div>
      </div>
      <div id="github-view-link">
        <img class="call-to-action-img" src="../../_static/images/pytorch-github.svg"/>
        <div class="call-to-action-desktop-view">View on GitHub</div>
        <div class="call-to-action-mobile-view">GitHub</div>
      </div>
    </div>

    
    
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-tts-tacotron2-pipeline-tutorial-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="text-to-speech-with-torchaudio-tacotron2">
<span id="sphx-glr-auto-examples-tts-tacotron2-pipeline-tutorial-py"></span><h1>Text-to-speech with torchaudio Tacotron2<a class="headerlink" href="#text-to-speech-with-torchaudio-tacotron2" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Author</strong> <a class="reference external" href="https://github.com/yangarbiter">Yao-Yuan Yang</a>,
<a class="reference external" href="mailto:moto&#37;&#52;&#48;fb&#46;com">Moto Hira</a></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">Â¶</a></h2>
<p>This tutorial shows how to build text-to-speech pipeline, using the
pretrained Tacotron2 in torchaudio.</p>
<p>The text-to-speech pipeline goes as follows:</p>
<ol class="arabic">
<li><p>Text preprocessing</p>
<p>First, the input text is encoded into a list of symbols. In this
tutorial, we will use English characters and phonemes as the symbols.</p>
</li>
<li><p>Spectrogram generation</p>
<p>From the encoded text, a spectrogram is generated. We use <code class="docutils literal notranslate"><span class="pre">Tacotron2</span></code>
model for this.</p>
</li>
<li><p>Time-domain conversion</p>
<p>The last step is converting the spectrogram into the waveform. The
process to generate speech from spectrogram is also called Vocoder.
In this tutorial, three different vocoders are used,
<a class="reference external" href="https://pytorch.org/audio/stable/models/wavernn.html">WaveRNN</a>,
<a class="reference external" href="https://pytorch.org/audio/stable/transforms.html#griffinlim">Griffin-Lim</a>,
and
<a class="reference external" href="https://pytorch.org/hub/nvidia_deeplearningexamples_tacotron2/">Nvidiaâ€™s WaveGlow</a>.</p>
</li>
</ol>
<p>The following figure illustrates the whole process.</p>
<img alt="https://download.pytorch.org/torchaudio/tutorial-assets/tacotron2_tts_pipeline.png" src="https://download.pytorch.org/torchaudio/tutorial-assets/tacotron2_tts_pipeline.png" />
<p>All the related components are bundled in <a class="reference internal" href="../../pipelines.html#torchaudio.pipelines.Tacotron2TTSBundle" title="torchaudio.pipelines.Tacotron2TTSBundle"><code class="xref py py-func docutils literal notranslate"><span class="pre">torchaudio.pipelines.Tacotron2TTSBundle()</span></code></a>,
but this tutorial will also cover the process under the hood.</p>
</div>
<div class="section" id="preparation">
<h2>Preparation<a class="headerlink" href="#preparation" title="Permalink to this headline">Â¶</a></h2>
<p>First, we install the necessary dependencies. In addition to
<code class="docutils literal notranslate"><span class="pre">torchaudio</span></code>, <code class="docutils literal notranslate"><span class="pre">DeepPhonemizer</span></code> is required to perform phoneme-based
encoding.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># When running this example in notebook, install DeepPhonemizer</span>
<span class="c1"># !pip3 install deep_phonemizer</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">IPython</span>

<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">16.0</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">]</span>

<span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torchaudio</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>1.11.0.dev20211104+cpu
0.11.0.dev20211104+cpu
cpu
</pre></div>
</div>
</div>
<div class="section" id="text-processing">
<h2>Text Processing<a class="headerlink" href="#text-processing" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="character-based-encoding">
<h3>Character-based encoding<a class="headerlink" href="#character-based-encoding" title="Permalink to this headline">Â¶</a></h3>
<p>In this section, we will go through how the character-based encoding
works.</p>
<p>Since the pre-trained Tacotron2 model expects specific set of symbol
tables, the same functionalities available in <code class="docutils literal notranslate"><span class="pre">torchaudio</span></code>. This
section is more for the explanation of the basis of encoding.</p>
<p>Firstly, we define the set of symbols. For example, we can use
<code class="docutils literal notranslate"><span class="pre">'_-!\'(),.:;?</span> <span class="pre">abcdefghijklmnopqrstuvwxyz'</span></code>. Then, we will map the
each character of the input text into the index of the corresponding
symbol in the table.</p>
<p>The following is an example of such processing. In the example, symbols
that are not in the table are ignored.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">symbols</span> <span class="o">=</span> <span class="s1">&#39;_-!</span><span class="se">\&#39;</span><span class="s1">(),.:;? abcdefghijklmnopqrstuvwxyz&#39;</span>
<span class="n">look_up</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">symbols</span><span class="p">)}</span>
<span class="n">symbols</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">symbols</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">text_to_sequence</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">look_up</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">symbols</span><span class="p">]</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello world! Text to speech!&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text_to_sequence</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[19, 16, 23, 23, 26, 11, 34, 26, 29, 23, 15, 2, 11, 31, 16, 35, 31, 11, 31, 26, 11, 30, 27, 16, 16, 14, 19, 2]
</pre></div>
</div>
<p>As mentioned in the above, the symbol table and indices must match
what the pretrained Tacotron2 model expects. <code class="docutils literal notranslate"><span class="pre">torchaudio</span></code> provides the
transform along with the pretrained model. For example, you can
instantiate and use such transform as follow.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">processor</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">TACOTRON2_WAVERNN_CHAR_LJSPEECH</span><span class="o">.</span><span class="n">get_text_processor</span><span class="p">()</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello world! Text to speech!&quot;</span>
<span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">processed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>tensor([[19, 16, 23, 23, 26, 11, 34, 26, 29, 23, 15,  2, 11, 31, 16, 35, 31, 11,
         31, 26, 11, 30, 27, 16, 16, 14, 19,  2]])
tensor([28], dtype=torch.int32)
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">processor</span></code> object takes either a text or list of texts as inputs.
When a list of texts are provided, the returned <code class="docutils literal notranslate"><span class="pre">lengths</span></code> variable
represents the valid length of each processed tokens in the output
batch.</p>
<p>The intermediate representation can be retrieved as follow.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">([</span><span class="n">processor</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">processed</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="n">lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;h&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39; &#39;, &#39;w&#39;, &#39;o&#39;, &#39;r&#39;, &#39;l&#39;, &#39;d&#39;, &#39;!&#39;, &#39; &#39;, &#39;t&#39;, &#39;e&#39;, &#39;x&#39;, &#39;t&#39;, &#39; &#39;, &#39;t&#39;, &#39;o&#39;, &#39; &#39;, &#39;s&#39;, &#39;p&#39;, &#39;e&#39;, &#39;e&#39;, &#39;c&#39;, &#39;h&#39;, &#39;!&#39;]
</pre></div>
</div>
</div>
<div class="section" id="phoneme-based-encoding">
<h3>Phoneme-based encoding<a class="headerlink" href="#phoneme-based-encoding" title="Permalink to this headline">Â¶</a></h3>
<p>Phoneme-based encoding is similar to character-based encoding, but it
uses a symbol table based on phonemes and a G2P (Grapheme-to-Phoneme)
model.</p>
<p>The detail of the G2P model is out of scope of this tutorial, we will
just look at what the conversion looks like.</p>
<p>Similar to the case of character-based encoding, the encoding process is
expected to match what a pretrained Tacotron2 model is trained on.
<code class="docutils literal notranslate"><span class="pre">torchaudio</span></code> has an interface to create the process.</p>
<p>The following code illustrates how to make and use the process. Behind
the scene, a G2P model is created using <code class="docutils literal notranslate"><span class="pre">DeepPhonemizer</span></code> package, and
the pretrained weights published by the author of <code class="docutils literal notranslate"><span class="pre">DeepPhonemizer</span></code> is
fetched.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bundle</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">TACOTRON2_WAVERNN_PHONE_LJSPEECH</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_text_processor</span><span class="p">()</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello world! Text to speech!&quot;</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">processed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0.00/63.6M [00:00&lt;?, ?B/s]
  0%|          | 56.0k/63.6M [00:00&lt;03:24, 326kB/s]
  0%|          | 192k/63.6M [00:00&lt;01:52, 594kB/s]
  1%|1         | 720k/63.6M [00:00&lt;00:38, 1.71MB/s]
  3%|2         | 1.90M/63.6M [00:00&lt;00:15, 4.23MB/s]
  6%|6         | 3.89M/63.6M [00:00&lt;00:07, 7.85MB/s]
 10%|9         | 6.34M/63.6M [00:00&lt;00:05, 11.4MB/s]
 13%|#3        | 8.31M/63.6M [00:01&lt;00:04, 12.6MB/s]
 17%|#6        | 10.8M/63.6M [00:01&lt;00:03, 14.7MB/s]
 20%|#9        | 12.7M/63.6M [00:01&lt;00:03, 15.0MB/s]
 24%|##3       | 15.2M/63.6M [00:01&lt;00:03, 16.1MB/s]
 27%|##6       | 17.1M/63.6M [00:01&lt;00:03, 16.0MB/s]
 31%|###       | 19.6M/63.6M [00:01&lt;00:02, 18.4MB/s]
 34%|###3      | 21.4M/63.6M [00:01&lt;00:02, 17.2MB/s]
 36%|###6      | 23.1M/63.6M [00:01&lt;00:02, 16.1MB/s]
 40%|####      | 25.6M/63.6M [00:02&lt;00:02, 18.5MB/s]
 43%|####3     | 27.4M/63.6M [00:02&lt;00:02, 17.4MB/s]
 46%|####5     | 29.1M/63.6M [00:02&lt;00:02, 16.2MB/s]
 50%|####9     | 31.6M/63.6M [00:02&lt;00:01, 17.3MB/s]
 52%|#####2    | 33.4M/63.6M [00:02&lt;00:01, 16.5MB/s]
 56%|#####5    | 35.5M/63.6M [00:02&lt;00:01, 17.9MB/s]
 59%|#####8    | 37.5M/63.6M [00:02&lt;00:01, 17.3MB/s]
 62%|######1   | 39.3M/63.6M [00:02&lt;00:01, 16.7MB/s]
 65%|######5   | 41.5M/63.6M [00:03&lt;00:01, 18.1MB/s]
 68%|######8   | 43.3M/63.6M [00:03&lt;00:01, 17.2MB/s]
 71%|#######1  | 45.2M/63.6M [00:03&lt;00:01, 17.9MB/s]
 74%|#######3  | 47.0M/63.6M [00:03&lt;00:01, 16.7MB/s]
 77%|#######7  | 49.2M/63.6M [00:03&lt;00:00, 17.2MB/s]
 80%|########  | 51.1M/63.6M [00:03&lt;00:00, 17.9MB/s]
 83%|########3 | 52.9M/63.6M [00:03&lt;00:00, 16.7MB/s]
 87%|########6 | 55.2M/63.6M [00:03&lt;00:00, 17.4MB/s]
 90%|########9 | 57.0M/63.6M [00:03&lt;00:00, 17.8MB/s]
 92%|#########2| 58.7M/63.6M [00:04&lt;00:00, 16.7MB/s]
 96%|#########5| 61.1M/63.6M [00:04&lt;00:00, 17.4MB/s]
 99%|#########8| 63.0M/63.6M [00:04&lt;00:00, 18.0MB/s]
100%|##########| 63.6M/63.6M [00:04&lt;00:00, 15.2MB/s]
tensor([[54, 20, 65, 69, 11, 92, 44, 65, 38,  2, 11, 81, 40, 64, 79, 81, 11, 81,
         20, 11, 79, 77, 59, 37,  2]])
tensor([25], dtype=torch.int32)
</pre></div>
</div>
<p>Notice that the encoded values are different from the example of
character-based encoding.</p>
<p>The intermediate representation looks like the following.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">([</span><span class="n">processor</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">processed</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="n">lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">]]])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;HH&#39;, &#39;AH&#39;, &#39;L&#39;, &#39;OW&#39;, &#39; &#39;, &#39;W&#39;, &#39;ER&#39;, &#39;L&#39;, &#39;D&#39;, &#39;!&#39;, &#39; &#39;, &#39;T&#39;, &#39;EH&#39;, &#39;K&#39;, &#39;S&#39;, &#39;T&#39;, &#39; &#39;, &#39;T&#39;, &#39;AH&#39;, &#39; &#39;, &#39;S&#39;, &#39;P&#39;, &#39;IY&#39;, &#39;CH&#39;, &#39;!&#39;]
</pre></div>
</div>
</div>
</div>
<div class="section" id="spectrogram-generation">
<h2>Spectrogram Generation<a class="headerlink" href="#spectrogram-generation" title="Permalink to this headline">Â¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Tacotron2</span></code> is the model we use to generate spectrogram from the
encoded text. For the detail of the model, please refer to <a class="reference external" href="https://arxiv.org/abs/1712.05884">the
paper</a>.</p>
<p>It is easy to instantiate a Tacotron2 model with pretrained weight,
however, note that the input to Tacotron2 models need to be processed
by the matching text processor.</p>
<p><a class="reference internal" href="../../pipelines.html#torchaudio.pipelines.Tacotron2TTSBundle" title="torchaudio.pipelines.Tacotron2TTSBundle"><code class="xref py py-func docutils literal notranslate"><span class="pre">torchaudio.pipelines.Tacotron2TTSBundle()</span></code></a> bundles the matching
models and processors together so that it is easy to create the pipeline.</p>
<p>For the available bundles, and its usage, please refer to <a class="reference internal" href="../../pipelines.html#module-torchaudio.pipelines" title="torchaudio.pipelines"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torchaudio.pipelines</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bundle</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">TACOTRON2_WAVERNN_PHONE_LJSPEECH</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_text_processor</span><span class="p">()</span>
<span class="n">tacotron2</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_tacotron2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello world! Text to speech!&quot;</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">spec</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tacotron2</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_tacotron2_pipeline_tutorial_001.png" srcset="../../_images/sphx_glr_tacotron2_pipeline_tutorial_001.png" alt="tacotron2 pipeline tutorial" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/torchaudio/models/tacotron2_english_phonemes_1500_epochs_wavernn_ljspeech.pth&quot; to /root/.cache/torch/hub/checkpoints/tacotron2_english_phonemes_1500_epochs_wavernn_ljspeech.pth

  0%|          | 0.00/107M [00:00&lt;?, ?B/s]
  7%|6         | 7.19M/107M [00:00&lt;00:01, 74.1MB/s]
 14%|#3        | 15.0M/107M [00:00&lt;00:01, 78.3MB/s]
 21%|##        | 22.5M/107M [00:00&lt;00:01, 60.8MB/s]
 27%|##6       | 28.8M/107M [00:00&lt;00:01, 62.7MB/s]
 33%|###3      | 35.7M/107M [00:00&lt;00:01, 65.8MB/s]
 40%|####      | 43.2M/107M [00:00&lt;00:00, 69.9MB/s]
 47%|####6     | 50.1M/107M [00:00&lt;00:00, 67.5MB/s]
 53%|#####2    | 56.6M/107M [00:00&lt;00:00, 67.4MB/s]
 59%|#####8    | 63.3M/107M [00:00&lt;00:00, 67.9MB/s]
 66%|######5   | 70.4M/107M [00:01&lt;00:00, 69.8MB/s]
 72%|#######1  | 77.1M/107M [00:01&lt;00:00, 68.9MB/s]
 78%|#######7  | 83.8M/107M [00:01&lt;00:00, 68.2MB/s]
 84%|########3 | 90.3M/107M [00:01&lt;00:00, 67.0MB/s]
 90%|########9 | 96.7M/107M [00:01&lt;00:00, 67.2MB/s]
 97%|#########6| 104M/107M [00:01&lt;00:00, 69.6MB/s]
100%|##########| 107M/107M [00:01&lt;00:00, 68.2MB/s]

&lt;matplotlib.image.AxesImage object at 0x7f02b2204520&gt;
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">Tacotron2.infer</span></code> method perfoms multinomial sampling,
therefor, the process of generating the spectrogram incurs randomness.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mf">4.3</span> <span class="o">*</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
    <span class="n">spec</span><span class="p">,</span> <span class="n">spec_lengths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tacotron2</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_tacotron2_pipeline_tutorial_002.png" srcset="../../_images/sphx_glr_tacotron2_pipeline_tutorial_002.png" alt="tacotron2 pipeline tutorial" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([80, 155])
torch.Size([80, 167])
torch.Size([80, 164])
</pre></div>
</div>
</div>
<div class="section" id="waveform-generation">
<h2>Waveform Generation<a class="headerlink" href="#waveform-generation" title="Permalink to this headline">Â¶</a></h2>
<p>Once the spectrogram is generated, the last process is to recover the
waveform from the spectrogram.</p>
<p><code class="docutils literal notranslate"><span class="pre">torchaudio</span></code> provides vocoders based on <code class="docutils literal notranslate"><span class="pre">GriffinLim</span></code> and
<code class="docutils literal notranslate"><span class="pre">WaveRNN</span></code>.</p>
<div class="section" id="wavernn">
<h3>WaveRNN<a class="headerlink" href="#wavernn" title="Permalink to this headline">Â¶</a></h3>
<p>Continuing from the previous section, we can instantiate the matching
WaveRNN model from the same bundle.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bundle</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">TACOTRON2_WAVERNN_PHONE_LJSPEECH</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_text_processor</span><span class="p">()</span>
<span class="n">tacotron2</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_tacotron2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">vocoder</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_vocoder</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello world! Text to speech!&quot;</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">spec</span><span class="p">,</span> <span class="n">spec_lengths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tacotron2</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
  <span class="n">waveforms</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">vocoder</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">spec_lengths</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">]</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">torchaudio</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output_wavernn.wav&quot;</span><span class="p">,</span> <span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">sample_rate</span><span class="o">=</span><span class="n">vocoder</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="s2">&quot;output_wavernn.wav&quot;</span><span class="p">))</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_tacotron2_pipeline_tutorial_003.png" srcset="../../_images/sphx_glr_tacotron2_pipeline_tutorial_003.png" alt="tacotron2 pipeline tutorial" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/torchaudio/models/wavernn_10k_epochs_8bits_ljspeech.pth&quot; to /root/.cache/torch/hub/checkpoints/wavernn_10k_epochs_8bits_ljspeech.pth

  0%|          | 0.00/16.7M [00:00&lt;?, ?B/s]
 40%|####      | 6.69M/16.7M [00:00&lt;00:00, 70.1MB/s]
 84%|########3 | 13.9M/16.7M [00:00&lt;00:00, 73.5MB/s]
100%|##########| 16.7M/16.7M [00:00&lt;00:00, 73.8MB/s]
&lt;IPython.lib.display.Audio object&gt;
</pre></div>
</div>
</div>
<div class="section" id="griffin-lim">
<h3>Griffin-Lim<a class="headerlink" href="#griffin-lim" title="Permalink to this headline">Â¶</a></h3>
<p>Using the Griffin-Lim vocoder is same as WaveRNN. You can instantiate
the vocode object with <code class="docutils literal notranslate"><span class="pre">get_vocoder</span></code> method and pass the spectrogram.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bundle</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">pipelines</span><span class="o">.</span><span class="n">TACOTRON2_GRIFFINLIM_PHONE_LJSPEECH</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_text_processor</span><span class="p">()</span>
<span class="n">tacotron2</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_tacotron2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">vocoder</span> <span class="o">=</span> <span class="n">bundle</span><span class="o">.</span><span class="n">get_vocoder</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
  <span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">spec</span><span class="p">,</span> <span class="n">spec_lengths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tacotron2</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">processed</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
<span class="n">waveforms</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">vocoder</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">spec_lengths</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">]</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">torchaudio</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output_griffinlim.wav&quot;</span><span class="p">,</span> <span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">sample_rate</span><span class="o">=</span><span class="n">vocoder</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="s2">&quot;output_griffinlim.wav&quot;</span><span class="p">))</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_tacotron2_pipeline_tutorial_004.png" srcset="../../_images/sphx_glr_tacotron2_pipeline_tutorial_004.png" alt="tacotron2 pipeline tutorial" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/torchaudio/models/tacotron2_english_phonemes_1500_epochs_ljspeech.pth&quot; to /root/.cache/torch/hub/checkpoints/tacotron2_english_phonemes_1500_epochs_ljspeech.pth

  0%|          | 0.00/107M [00:00&lt;?, ?B/s]
  7%|6         | 7.31M/107M [00:00&lt;00:01, 76.5MB/s]
 14%|#3        | 14.6M/107M [00:00&lt;00:01, 65.8MB/s]
 20%|##        | 22.0M/107M [00:00&lt;00:01, 70.7MB/s]
 28%|##7       | 29.7M/107M [00:00&lt;00:01, 74.5MB/s]
 34%|###4      | 36.9M/107M [00:00&lt;00:01, 73.9MB/s]
 41%|####1     | 44.4M/107M [00:00&lt;00:00, 75.3MB/s]
 49%|####8     | 52.3M/107M [00:00&lt;00:00, 77.7MB/s]
 56%|#####5    | 59.9M/107M [00:00&lt;00:00, 78.6MB/s]
 63%|######2   | 67.5M/107M [00:00&lt;00:00, 78.5MB/s]
 70%|######9   | 75.0M/107M [00:01&lt;00:00, 76.5MB/s]
 77%|#######6  | 82.3M/107M [00:01&lt;00:00, 73.3MB/s]
 83%|########3 | 89.3M/107M [00:01&lt;00:00, 70.0MB/s]
 90%|######### | 97.0M/107M [00:01&lt;00:00, 73.1MB/s]
 97%|#########7| 104M/107M [00:01&lt;00:00, 74.1MB/s]
100%|##########| 107M/107M [00:01&lt;00:00, 74.3MB/s]
&lt;IPython.lib.display.Audio object&gt;
</pre></div>
</div>
</div>
<div class="section" id="waveglow">
<h3>Waveglow<a class="headerlink" href="#waveglow" title="Permalink to this headline">Â¶</a></h3>
<p>Waveglow is a vocoder published by Nvidia. The pretrained weight is
publishe on Torch Hub. One can instantiate the model using <code class="docutils literal notranslate"><span class="pre">torch.hub</span></code>
module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Workaround to load model mapped on GPU</span>
<span class="c1"># https://stackoverflow.com/a/61840832</span>
<span class="n">waveglow</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;NVIDIA/DeepLearningExamples:torchhub&#39;</span><span class="p">,</span> <span class="s1">&#39;nvidia_waveglow&#39;</span><span class="p">,</span> <span class="n">model_math</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="s1">&#39;https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth&#39;</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;module.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="n">waveglow</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
<span class="n">waveglow</span> <span class="o">=</span> <span class="n">waveglow</span><span class="o">.</span><span class="n">remove_weightnorm</span><span class="p">(</span><span class="n">waveglow</span><span class="p">)</span>
<span class="n">waveglow</span> <span class="o">=</span> <span class="n">waveglow</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">waveglow</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">waveforms</span> <span class="o">=</span> <span class="n">waveglow</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">[</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">]</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">spec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

<span class="n">torchaudio</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;output_waveglow.wav&quot;</span><span class="p">,</span> <span class="n">waveforms</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">22050</span><span class="p">)</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="s2">&quot;output_waveglow.wav&quot;</span><span class="p">))</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_tacotron2_pipeline_tutorial_005.png" srcset="../../_images/sphx_glr_tacotron2_pipeline_tutorial_005.png" alt="tacotron2 pipeline tutorial" class = "sphx-glr-single-img"/><p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://github.com/NVIDIA/DeepLearningExamples/archive/torchhub.zip&quot; to /root/.cache/torch/hub/torchhub.zip
/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/SpeechSynthesis/Tacotron2/waveglow/model.py:55: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter &#39;some&#39; has been replaced with a string parameter &#39;mode&#39;.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, &#39;reduced&#39; if some else &#39;complete&#39;) (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1949.)
  W = torch.qr(torch.FloatTensor(c, c).normal_())[0]
Downloading: &quot;https://api.ngc.nvidia.com/v2/models/nvidia/waveglowpyt_fp32/versions/1/files/nvidia_waveglowpyt_fp32_20190306.pth&quot; to /root/.cache/torch/hub/checkpoints/nvidia_waveglowpyt_fp32_20190306.pth
&lt;IPython.lib.display.Audio object&gt;
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 2 minutes  41.785 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-tts-tacotron2-pipeline-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a23c744f813eb1595df353bc60141b76/tacotron2_pipeline_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tacotron2_pipeline_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e4c73b9100927d3fb664e426fefeecec/tacotron2_pipeline_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tacotron2_pipeline_tutorial.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="index.html" class="btn btn-neutral" title="Text-to-Speech" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torchaudio Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Text-to-speech with torchaudio Tacotron2</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#preparation">Preparation</a></li>
<li><a class="reference internal" href="#text-processing">Text Processing</a><ul>
<li><a class="reference internal" href="#character-based-encoding">Character-based encoding</a></li>
<li><a class="reference internal" href="#phoneme-based-encoding">Phoneme-based encoding</a></li>
</ul>
</li>
<li><a class="reference internal" href="#spectrogram-generation">Spectrogram Generation</a></li>
<li><a class="reference internal" href="#waveform-generation">Waveform Generation</a><ul>
<li><a class="reference internal" href="#wavernn">WaveRNN</a></li>
<li><a class="reference internal" href="#griffin-lim">Griffin-Lim</a></li>
<li><a class="reference internal" href="#waveglow">Waveglow</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
         <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
         <script src="../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

     
    <script type="text/javascript">
      $(document).ready(function() {
	  var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
	  if (downloadNote.length >= 1) {
	      var tutorialUrlArray = $("#tutorial-type").text().split('/').slice(1);
	      var githubLink = "https://github.com/pytorch/audio/blob/main/examples/gallery/"  + tutorialUrlArray.join("/") + ".py",
		  notebookLink = $(".reference.download")[1].href,
		  notebookDownloadPath = notebookLink.split('_downloads')[1],
		  colabLink = "https://colab.research.google.com/github/pytorch/audio/blob/gh-pages/main/_downloads" + notebookDownloadPath;

	      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
	      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
	  }
      });
    </script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>